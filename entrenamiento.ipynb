{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador Binario de Imagenes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Empleada\n",
    "El proceso de entrenamiento de una Red Neuronal Artificial (RNA) implica la utilización de conjuntos de datos robustos y bien organizados. En este caso, se hace uso del repositorio [Cat and Dog](https://www.kaggle.com/datasets/tongpython/cat-and-dog?select=test_set) disponible en Kaggle. Este repositorio es una fuente confiable que alberga una amplia gama de imágenes de gatos y perros, ofreciendo una colección de datos de alta calidad que están debidamente clasificados.\n",
    "\n",
    "La calidad y la cantidad de datos disponibles son aspectos fundamentales para el éxito del entrenamiento de la RNA. En el caso de este repositorio, la diversidad y el tamaño del conjunto de imágenes permiten que la RNA aprenda patrones medianamente complejos. Además, la clasificación adecuada de las imágenes en categorías específicas (gatos y perros) facilita el proceso de **aprendizaje supervisado**, ya que la RNA puede distinguir y asociar características específicas con cada clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias empleadas\n",
    "### Tensorflow\n",
    "TensorFlow es una biblioteca de código abierto desarrollada por Google que se utiliza principalmente para tareas de aprendizaje automático y computación numérica. Proporciona un entorno para construir y entrenar modelos de aprendizaje automático, incluyendo redes neuronales profundas, de manera eficiente.\n",
    "\n",
    "Esta plataforma ofrece flexibilidad y escalabilidad, lo que la hace adecuada para una amplia gama de aplicaciones de aprendizaje automático, desde el procesamiento del lenguaje natural y la visión por computadora hasta el reconocimiento de voz, entre otros campos. TensorFlow también cuenta con herramientas y APIs que facilitan la implementación de modelos en diferentes entornos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo empleado\n",
    "Las capas en orden son:\n",
    "Capa convolucional con 32 filtros de 3x3, seguida de una capa de max pooling.  \n",
    "Capa convolucional con 64 filtros de 3x3, seguida de una capa de max pooling.  \n",
    "Capa convolucional con 128 filtros de 3x3, seguida de una capa de max pooling.  \n",
    "Capa densa con 128 neuronas y activación 'relu' (Rectified Linear Unit).  \n",
    "La función ReLU se define como:\n",
    "f(x) = max(0, x)  \n",
    "Capa de salida densa con 1 neurona y activación 'sigmoid' para problemas de clasificación binaria.\n",
    "En resumen, hay tres capas convolucionales/max pooling y dos capas densas, lo que suma un total de cinco capas ocultas en esta red neuronal convolucional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    modelo = Sequential()\n",
    "    modelo.add(Conv2D(32, (3, 3), input_shape=(128, 128, 3), activation='relu'))\n",
    "    modelo.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    modelo.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    modelo.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    modelo.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    modelo.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    modelo.add(Flatten())\n",
    "    modelo.add(Dense(128, activation='relu'))\n",
    "    modelo.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    modelo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de Imagenes\n",
    "### Transformar y aumentar data\n",
    "El método `create_data_generator()` crea un generador de datos para preprocesar y aumentar imágenes para el entrenamiento de un modelo de red neuronal convolucional (CNN). En este caso, utiliza la clase ImageDataGenerator proporcionada por la librería Keras para generar lotes de imágenes con ciertas transformaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_generator():\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                       shear_range=0.2,\n",
    "                                       zoom_range=0.2,\n",
    "                                       horizontal_flip=True)\n",
    "    return train_datagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ruta de Las Imagenes de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_directorio_entrenamiento = 'dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generador de imagenes aptas para entrenamiento\n",
    "El método `create_data_flow(train_datagen)` crea un flujo de datos para el entrenamiento de un modelo de red neuronal convolucional utilizando el generador de datos train_datagen que se pasa como argumento.\n",
    "\n",
    "Este método utiliza la función flow_from_directory() de la clase ImageDataGenerator en Keras/TensorFlow para generar un flujo de datos a partir de un directorio que contiene las imágenes de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_flow(train_datagen):\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        ruta_directorio_entrenamiento,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        class_mode='binary'\n",
    "    )\n",
    "    return train_generator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo de RNA\n",
    "El método ``train_model()`` es una función diseñada para entrenar un modelo de red neuronal utilizando el generador de flujo de datos train_generator. Aquí se emplea el método fit() de Keras para entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_generator, epochs, steps_per_epoch):\n",
    "    model.fit(train_generator, epochs=epochs, steps_per_epoch=steps_per_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Almacenamiento de la informacion obtenida del entrenamiento (pesos)\n",
    "Guarda los pesos y la estructura del modelo en un archivo con extensión .h5 mediante el método model.save(model_name + '.h5'). Este archivo .h5 contendrá toda la información necesaria para **recrear** el modelo, incluyendo los pesos de las diferentes capas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name):\n",
    "    model.save(model_name + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuracion del Entrenamiento\n",
    "- Configuración de hiperparámetros y creación del modelo  \n",
    "- Generación de datos de entrenamiento  \n",
    "- Creación de un flujo de datos de entrenamiento  \n",
    "- Determinación de pasos por época  \n",
    "- Entrenamiento del modelo  \n",
    "\n",
    "El modelo se entrena utilizando la función train_model() con los argumentos del modelo, el generador de flujo de datos de entrenamiento, el número de épocas y los pasos por época. Durante este proceso, el modelo se ajusta a los datos de entrenamiento para **aprender patrones** y **realizar actualizaciones de pesos** en cada época durante 10 iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "model = build_model()\n",
    "train_datagen = create_data_generator()\n",
    "train_generator = create_data_flow(train_datagen) \n",
    "steps_per_epoch = len(train_generator)\n",
    "\n",
    "train_model(model, train_generator, epochs, steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado con información adicional\n",
    "save_model(model, 'modelo_perro_gato')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
